{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MTS_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSM8-isNr8ys"
      },
      "source": [
        "# **Data-driven Spatio-temporal Prediction of COVID-19 Pandemic Using an LSTM Network: A County-level Analysis in the US**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvt5hRDkwYVk",
        "outputId": "d6128f13-f350-42ba-a823-b63c1965b187"
      },
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "from tensorflow import experimental\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Google Colab Pro were used for training: Hardware Accelerator: GPU, Runtime Shape: High-RAM\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at gdrive; to attempt to forcibly remount, call drive.mount(\"gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WkgIBELEeg7"
      },
      "source": [
        "def predict_multistep_timeseries(df, counties, mean, std, model):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "        df: A dataframe of multiple time series\n",
        "        counties: A list of counties \n",
        "        mean: Train set mean\n",
        "        std: Train set std\n",
        "        model: MTS-LSTM trained model\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "        seriesall: Dynamics predictions\n",
        "\n",
        "    '''\n",
        "    \n",
        "    seriesall = np.zeros((len(counties), TIMESERIES_LENGHT - WINDOW_SIZE, len(VARIABLES)))\n",
        "    counter = 0\n",
        "    for county in counties:\n",
        "        mask = df.loc[:, 'GISJOIN'] == county\n",
        "        d = df.loc[mask, VARIABLES]\n",
        "        series = d.to_numpy()\n",
        "        # Standardize input observations\n",
        "        series = (series-mean) / std\n",
        "        # Remove a number of observations from the beginning based on window size. \n",
        "        forecasts = series[WINDOW_SIZE:, :]\n",
        "\n",
        "        # Forecast 4 weeks ahead\n",
        "        for i in range(1, PRED_WEEKS + 1):\n",
        "            ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "            ds = ds.window(WINDOW_SIZE + 1, shift=1, drop_remainder=True)\n",
        "            ds = ds.flat_map(lambda w: w.batch(WINDOW_SIZE + 1))\n",
        "            ds2 = ds.map(lambda w: (w[:-1], w[-1:, :len(VARIABLES)]))\n",
        "            ds3 = ds2.batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "            forecast = model.predict(ds3, use_multiprocessing=USE_MULTIPROCESSING)\n",
        "            lstm_forecast = forecast[:, -1, :]\n",
        "            lstm_forecast = np.concatenate((lstm_forecast[-1, :].reshape(1, len(VARIABLES))[0], \n",
        "                                            forecasts[-1, len(VARIABLES):]), axis=0)\n",
        "             \n",
        "            forecasts = np.concatenate((forecasts, np.array([lstm_forecast])))\n",
        "            series = forecasts\n",
        "\n",
        "        seriesall[counter, :, :] = series * std + mean\n",
        "        counter = counter + 1\n",
        "    \n",
        "    return seriesall\n",
        "\n",
        "def mean_variance_calculator(train_dataset):\n",
        "\n",
        "    '''\n",
        "    calculates mean and variance of the training set to standardize observations\n",
        "\n",
        "    Args:\n",
        "        train_dataset: Training set\n",
        "\n",
        "    Outputs:\n",
        "        [mean_train, std_train]: A list containing mean and standard deviation of training observations\n",
        "\n",
        "    '''\n",
        "\n",
        "    mean_train = np.mean(np.mean(list(train_dataset), axis=0), axis=0)\n",
        "    std_train=[]\n",
        "    for var in range(0, len(VARIABLES)):\n",
        "        aux_std = []\n",
        "        for item in train_dataset:\n",
        "            aux_std.append(np.array(item)[:, var])\n",
        "        std_train.append(np.std(np.array(aux_std)))\n",
        "\n",
        "    return [mean_train, std_train]\n",
        "    \n",
        "def create_feature_vector(counties_sample, data_train_valid):\n",
        "    '''\n",
        "    Prepares feature vectors from multiple time series.\n",
        "    Args:\n",
        "\n",
        "        counties_sample:  A list of sample counties\n",
        "        data_train_valid: A dataframe of multiple time series\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "        feature_vectors: Feature vectors prepared for training.\n",
        "    '''\n",
        "\n",
        "    # Create features for series of each county using a sliding window\n",
        "    for county in counties_sample:\n",
        "        mask = data_train_valid.loc[:, 'GISJOIN'] == county\n",
        "        d = data_train_valid.loc[mask, VARIABLES]\n",
        "        series = d.to_numpy()\n",
        "        ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "        \"\"\" \n",
        "        Use an extra step for window as the label. Make sure to drop the remainder \n",
        "        to avoid feature vectors of different length. Each feature vector has both \n",
        "        features and labels at this point.\n",
        "        \"\"\"\n",
        "        ds = ds.window(WINDOW_SIZE + 1, shift=1, drop_remainder=True)\n",
        "        ds = ds.flat_map(lambda w: w.batch(WINDOW_SIZE + 1))\n",
        "        if county == counties_sample[0]:\n",
        "            feature_vectors = ds\n",
        "        else:\n",
        "            feature_vectors = feature_vectors.concatenate(ds)\n",
        "\n",
        "    # Shuffle feature vectors from different series. \n",
        "    # Use the number of features to choose proper shuffle size \n",
        "    if SHUFFLE_TIMESERIES:\n",
        "        shuffle_buffer = 1\n",
        "        for item in feature_vectors:\n",
        "            shuffle_buffer = shuffle_buffer + 1 \n",
        "        return feature_vectors.shuffle(shuffle_buffer)\n",
        "    else:\n",
        "        return feature_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WorLly1RNqwM"
      },
      "source": [
        "# Input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcoyNB86NI60",
        "outputId": "e9c24f12-7fd9-4272-d7ab-c116f5eedbce"
      },
      "source": [
        "# The length of timeseries for a county\n",
        "TIMESERIES_LENGHT = 33 \n",
        "# Use this variable to control the proportion of counties that are used in training process\n",
        "PROP_SAMPLE_COUNTIES = 0.016 \n",
        "# Number of weeks from which new predictionsa re made\n",
        "WINDOW_SIZE = 3  \n",
        "# Number of weeks to be predicted\n",
        "PRED_WEEKS = 4 \n",
        "# Variables to be used in the model\n",
        "VARIABLES = ['confirmed_cases', 'deaths', 'foot_traffic'] \n",
        "# Whether or not shuffle the feature vectors from different counties\n",
        "SHUFFLE_TIMESERIES = 1\n",
        "BATCH_SIZE = 1024 \n",
        "LEARNING_RATE = 1e-3\n",
        "BETA_1 = 0.9\n",
        "BETA_2 = 0.999\n",
        "EPSILON =1e-07\n",
        "AMSGRAD = False\n",
        "EPOCHS = 100\n",
        "USE_MULTIPROCESSING = True\n",
        "\n",
        "# Read Covid-19 time series data for 01/26/2020-09/26/2020\n",
        "data = pd.read_csv('gdrive/MyDrive/ColabNotebooks/Covid19_01262020_09262020.zip', compression='zip') \n",
        "# 35 weeks of data is availbale in data set. The last two weeks are removed for the purpose of this research\n",
        "data = data[data.loc[:, 'Date'] <= 230] # Refer to the data description column (Date)\n",
        "\n",
        "# Randomly choose a proportion of counties for training using PROP_SAMPLE_COUNTIES variable \n",
        "counties = list(pd.unique(data.loc[:, 'GISJOIN']))\n",
        "counties_sample = random.sample(counties, \n",
        "                                int(np.floor(len(counties)*(PROP_SAMPLE_COUNTIES))))\n",
        "print('Training using ' + \n",
        "        str(len(counties_sample)) + \n",
        "        ' counties of ' + \n",
        "        str(len(counties)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training using 50 counties of 3142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzoH2zraNhGp"
      },
      "source": [
        "# Train-Validation-Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEsuiG14NVpd"
      },
      "source": [
        "''' \n",
        "Split dataset into train-validation, and test data sets. For selected counties, \n",
        "set aside the last four weeks for test and the rest for train-validation. Notice \n",
        "that in the end, we test the model for a four weeks horizon on the entire county sets.\n",
        "'''\n",
        "data_train_valid = data[data.loc[:, 'Date'] < 209]\n",
        "\n",
        "# Prepare timeseries for training and validation. Refer to figure 7 in paper\n",
        "feature_vectors = create_feature_vector(counties_sample, \n",
        "                                        data_train_valid)\n",
        "\n",
        "# Split feature vectors into train and validation (70%-30%)\n",
        "valid_dataset = feature_vectors.take(np.floor(0.3*len(list(feature_vectors)))) \n",
        "train_dataset = feature_vectors.skip(np.floor(0.3*len(list(feature_vectors))))\n",
        "\n",
        "# Standardize training and validation data using mean and variance of training set\n",
        "[mean_train, std_train] = mean_variance_calculator(train_dataset)\n",
        "train_dataset_stnd = train_dataset.map(lambda x: (x-mean_train) / std_train)\n",
        "valid_dataset_stnd = valid_dataset.map(lambda x: (x-mean_train) / std_train)\n",
        "\n",
        "# Separate features and labels for validation set. The last item in each series is used as label\n",
        "valid_dataset_stnd = valid_dataset_stnd.map(lambda w: (w[:-1], w[-1:, :len(VARIABLES)]))\n",
        "# Create batches of validation set\n",
        "valid_dataset_stnd= valid_dataset_stnd.batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "# Separate features and labels for training set. The last item in each series is used as label\n",
        "train_dataset_stnd = train_dataset_stnd.map(lambda w: (w[:-1], w[-1:, :len(VARIABLES)]))\n",
        "# Create batches of training set\n",
        "train_dataset_stnd= train_dataset_stnd.batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeazSzFANZ-y"
      },
      "source": [
        "# Defining the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bvSxXjElNyE2",
        "outputId": "73bb2be5-be20-47c7-bbd2-354fd3ded91c"
      },
      "source": [
        "# Using len(VARIABLE) control the number of input variables to the model.\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.BatchNormalization(input_shape=[None, len(VARIABLES)]),\n",
        "                                    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "                                    tf.keras.layers.LSTM(128, return_sequences=True), \n",
        "                                    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(len(VARIABLES)),\n",
        "                                    tf.keras.layers.Lambda(lambda x: x * 100)\n",
        "                                    ])\n",
        "\n",
        "# Find the best learning rate (1e-3 is used as optimized learning rate in this research)\n",
        "optimize_learning_rate = tf.keras.callbacks.LearningRateScheduler(\n",
        "lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate = LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2, \n",
        "    epsilon= EPSILON, amsgrad = AMSGRAD,)\n",
        "model.compile(loss=tf.keras.losses.Huber(), \n",
        "              optimizer=optimizer, \n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset_stnd, epochs=150, callbacks=[optimize_learning_rate]) \n",
        "plt.semilogx(history.history[\"lr\"], history.history[\"mae\"])\n",
        "# Choose appropriate range when using different scenarios\n",
        "plt.axis([1e-5, 1e-1, 0.15, 0.9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3970 - mae: 0.7143\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.4209 - mae: 0.7382\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.4463 - mae: 0.7665\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.4135 - mae: 0.7307\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.4015 - mae: 0.7199\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.4467 - mae: 0.7724\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.3931 - mae: 0.7100\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.3994 - mae: 0.7137\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4322 - mae: 0.7539\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.4268 - mae: 0.7462\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.4195 - mae: 0.7405\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4112 - mae: 0.7278\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.4038 - mae: 0.7207\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4161 - mae: 0.7338\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.4340 - mae: 0.7539\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.3863 - mae: 0.7021\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.3989 - mae: 0.7158\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.4326 - mae: 0.7495\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4094 - mae: 0.7264\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.4007 - mae: 0.7168\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.3967 - mae: 0.7116\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4188 - mae: 0.7365\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.4109 - mae: 0.7274\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.4014 - mae: 0.7164\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.4336 - mae: 0.7523\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.4339 - mae: 0.7528\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.4208 - mae: 0.7407\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.4140 - mae: 0.7293\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.4138 - mae: 0.7333\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4181 - mae: 0.7358\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.4236 - mae: 0.7415\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4310 - mae: 0.7501\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.3967 - mae: 0.7133\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.4232 - mae: 0.7405\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.4411 - mae: 0.7598\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.4147 - mae: 0.7324\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.3922 - mae: 0.7080\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.4011 - mae: 0.7133\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.3986 - mae: 0.7126\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.4174 - mae: 0.7332\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.3919 - mae: 0.7091\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.4437 - mae: 0.7625\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.4346 - mae: 0.7552\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.3865 - mae: 0.6993\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.4219 - mae: 0.7382\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.3992 - mae: 0.7122\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.3917 - mae: 0.7038\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.4012 - mae: 0.7125\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.4038 - mae: 0.7165\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.4117 - mae: 0.7232\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.3990 - mae: 0.7118\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.4108 - mae: 0.7256\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.4182 - mae: 0.7330\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.4042 - mae: 0.7135\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.3909 - mae: 0.6993\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.3976 - mae: 0.7118\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.3698 - mae: 0.6747\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.3692 - mae: 0.6774\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.3733 - mae: 0.6770\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.3914 - mae: 0.6956\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.3695 - mae: 0.6709\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.3689 - mae: 0.6668\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.3737 - mae: 0.6730\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.3555 - mae: 0.6505\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.3704 - mae: 0.6626\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.3629 - mae: 0.6531\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.3508 - mae: 0.6367\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.3516 - mae: 0.6347\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.3302 - mae: 0.6045\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.3256 - mae: 0.6016\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.3224 - mae: 0.5902\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.3328 - mae: 0.6015\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.2737 - mae: 0.5301\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.2937 - mae: 0.5495\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.2852 - mae: 0.5335\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.2937 - mae: 0.5386\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.2307 - mae: 0.4659\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.2399 - mae: 0.4669\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.2325 - mae: 0.4509\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.2277 - mae: 0.4459\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.2127 - mae: 0.4257\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.2285 - mae: 0.4421\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.2308 - mae: 0.4402\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.2132 - mae: 0.4109\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.2050 - mae: 0.3999\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.1849 - mae: 0.3724\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.1744 - mae: 0.3521\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.1549 - mae: 0.3230\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.1502 - mae: 0.3117\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.1666 - mae: 0.3278\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.1377 - mae: 0.2938\n",
            "Epoch 92/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.1447 - mae: 0.3000\n",
            "Epoch 93/150\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.1333 - mae: 0.2836\n",
            "Epoch 94/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.1425 - mae: 0.2899\n",
            "Epoch 95/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.1114 - mae: 0.2494\n",
            "Epoch 96/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.1214 - mae: 0.2568\n",
            "Epoch 97/150\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.1044 - mae: 0.2323\n",
            "Epoch 98/150\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.1226 - mae: 0.2503\n",
            "Epoch 99/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1122 - mae: 0.2377\n",
            "Epoch 100/150\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.1191 - mae: 0.2435\n",
            "Epoch 101/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.1145 - mae: 0.2425\n",
            "Epoch 102/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1251 - mae: 0.2537\n",
            "Epoch 103/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.1268 - mae: 0.2527\n",
            "Epoch 104/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1109 - mae: 0.2326\n",
            "Epoch 105/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0858 - mae: 0.2013\n",
            "Epoch 106/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.1113 - mae: 0.2283\n",
            "Epoch 107/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.1043 - mae: 0.2193\n",
            "Epoch 108/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.1010 - mae: 0.2244\n",
            "Epoch 109/150\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.1037 - mae: 0.2318\n",
            "Epoch 110/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1103 - mae: 0.2330\n",
            "Epoch 111/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0976 - mae: 0.2210\n",
            "Epoch 112/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.1127 - mae: 0.2283\n",
            "Epoch 113/150\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0810 - mae: 0.1912\n",
            "Epoch 114/150\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.0981 - mae: 0.2139\n",
            "Epoch 115/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0959 - mae: 0.2170\n",
            "Epoch 116/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0978 - mae: 0.2192\n",
            "Epoch 117/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.1039 - mae: 0.2252\n",
            "Epoch 118/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0971 - mae: 0.2224\n",
            "Epoch 119/150\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.1045 - mae: 0.2274\n",
            "Epoch 120/150\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.0876 - mae: 0.2129\n",
            "Epoch 121/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0996 - mae: 0.2318\n",
            "Epoch 122/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.1074 - mae: 0.2348\n",
            "Epoch 123/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.1125 - mae: 0.2704\n",
            "Epoch 124/150\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.1004 - mae: 0.2491\n",
            "Epoch 125/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.0862 - mae: 0.2171\n",
            "Epoch 126/150\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.0974 - mae: 0.2194\n",
            "Epoch 127/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0978 - mae: 0.2030\n",
            "Epoch 128/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1076 - mae: 0.2386\n",
            "Epoch 129/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.1390 - mae: 0.3210\n",
            "Epoch 130/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.1111 - mae: 0.2463\n",
            "Epoch 131/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0983 - mae: 0.2309\n",
            "Epoch 132/150\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.1328 - mae: 0.3394\n",
            "Epoch 133/150\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.1613 - mae: 0.3984\n",
            "Epoch 134/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.3185 - mae: 0.5908\n",
            "Epoch 135/150\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.8848 - mae: 1.2632\n",
            "Epoch 136/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.2217 - mae: 0.5489\n",
            "Epoch 137/150\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7112 - mae: 1.0239\n",
            "Epoch 138/150\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 1.4587 - mae: 1.8869\n",
            "Epoch 139/150\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.5546 - mae: 0.9496\n",
            "Epoch 140/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7400 - mae: 1.1856\n",
            "Epoch 141/150\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 5.4260 - mae: 5.9079\n",
            "Epoch 142/150\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 30.5712 - mae: 31.0688\n",
            "Epoch 143/150\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 54.7825 - mae: 55.2776\n",
            "Epoch 144/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 72.1985 - mae: 72.6984\n",
            "Epoch 145/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 52.6692 - mae: 53.1646\n",
            "Epoch 146/150\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 3.2652 - mae: 3.7638\n",
            "Epoch 147/150\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 8.7312 - mae: 9.2300\n",
            "Epoch 148/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 11.6581 - mae: 12.1580\n",
            "Epoch 149/150\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 1.2013 - mae: 1.6907\n",
            "Epoch 150/150\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 6.5217 - mae: 7.0200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1e-05, 0.1, 0.15, 0.9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlqQOxjUN-gW"
      },
      "source": [
        "# Training MTS-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ryLut9LpOItI",
        "outputId": "e201d95c-45a3-445d-89df-6a3975664d77"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.BatchNormalization(input_shape=[None, len(VARIABLES)]),\n",
        "                                    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "                                    tf.keras.layers.LSTM(128, return_sequences=True), \n",
        "                                    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(len(VARIABLES)),\n",
        "                                    tf.keras.layers.Lambda(lambda x: x * 100)\n",
        "                                    ])\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "print('Training...')\n",
        "# Set the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE, \n",
        "                                        beta_1=BETA_1, \n",
        "                                        beta_2=BETA_2, \n",
        "                                        epsilon= EPSILON, \n",
        "                                        amsgrad = AMSGRAD,)\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.Huber(), \n",
        "              optimizer=optimizer, \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset_stnd, \n",
        "                    epochs=EPOCHS, \n",
        "                    use_multiprocessing=USE_MULTIPROCESSING, \n",
        "                    validation_data=valid_dataset_stnd)\n",
        "\n",
        "# validate the model\n",
        "valid_loss, valid_mae = model.evaluate(valid_dataset_stnd, \n",
        "                                        batch_size=BATCH_SIZE, \n",
        "                                        use_multiprocessing=USE_MULTIPROCESSING)\n",
        "print('Validation loss: ' + \n",
        "        str(valid_loss), '\\n' 'Validation MAE: ' + \n",
        "        str(valid_mae))\n",
        "\n",
        "'''\n",
        "Notice that validation MAE is less than Training MAE. This is because the dropout \n",
        "layer is not applied in validation while training. To check out, drop the drop out layer from the model.\n",
        "'''\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.legend(['Training mae', 'Validation mae'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3476 - mae: 0.6357 - val_loss: 0.1326 - val_mae: 0.3830\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 1s 613ms/step - loss: 0.2248 - mae: 0.4887 - val_loss: 0.1200 - val_mae: 0.3007\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.1486 - mae: 0.3620 - val_loss: 0.1141 - val_mae: 0.3053\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 0.1414 - mae: 0.3463 - val_loss: 0.1024 - val_mae: 0.2903\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 0.1200 - mae: 0.3123 - val_loss: 0.1229 - val_mae: 0.2845\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 1s 616ms/step - loss: 0.1243 - mae: 0.2901 - val_loss: 0.0787 - val_mae: 0.2144\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.1059 - mae: 0.2492 - val_loss: 0.0831 - val_mae: 0.2107\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 1s 633ms/step - loss: 0.1078 - mae: 0.2387 - val_loss: 0.0669 - val_mae: 0.1840\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.1060 - mae: 0.2299 - val_loss: 0.0934 - val_mae: 0.2144\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 1s 613ms/step - loss: 0.1041 - mae: 0.2183 - val_loss: 0.0825 - val_mae: 0.1902\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 1s 620ms/step - loss: 0.1167 - mae: 0.2325 - val_loss: 0.0640 - val_mae: 0.1617\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.1068 - mae: 0.2153 - val_loss: 0.0539 - val_mae: 0.1429\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.0937 - mae: 0.2005 - val_loss: 0.0743 - val_mae: 0.1633\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 0.0963 - mae: 0.1977 - val_loss: 0.0780 - val_mae: 0.1662\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.0959 - mae: 0.2005 - val_loss: 0.0494 - val_mae: 0.1465\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.0890 - mae: 0.2048 - val_loss: 0.0918 - val_mae: 0.2029\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 1s 615ms/step - loss: 0.1060 - mae: 0.2273 - val_loss: 0.0776 - val_mae: 0.1945\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.0891 - mae: 0.2135 - val_loss: 0.0727 - val_mae: 0.1847\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 1s 613ms/step - loss: 0.1055 - mae: 0.2324 - val_loss: 0.0613 - val_mae: 0.1759\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 1s 616ms/step - loss: 0.0888 - mae: 0.2119 - val_loss: 0.0406 - val_mae: 0.1475\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 1s 633ms/step - loss: 0.0808 - mae: 0.2013 - val_loss: 0.0734 - val_mae: 0.1855\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 0.0927 - mae: 0.2112 - val_loss: 0.0623 - val_mae: 0.1700\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.1022 - mae: 0.2204 - val_loss: 0.0714 - val_mae: 0.1774\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.0946 - mae: 0.2094 - val_loss: 0.0788 - val_mae: 0.1865\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 0.0966 - mae: 0.2146 - val_loss: 0.0495 - val_mae: 0.1520\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.0881 - mae: 0.2061 - val_loss: 0.0484 - val_mae: 0.1486\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.0933 - mae: 0.2110 - val_loss: 0.0519 - val_mae: 0.1527\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 1s 635ms/step - loss: 0.0895 - mae: 0.2071 - val_loss: 0.0685 - val_mae: 0.1736\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 0.0795 - mae: 0.1973 - val_loss: 0.0373 - val_mae: 0.1352\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 1s 624ms/step - loss: 0.0943 - mae: 0.2091 - val_loss: 0.0536 - val_mae: 0.1553\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 1s 627ms/step - loss: 0.0816 - mae: 0.1923 - val_loss: 0.0571 - val_mae: 0.1603\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 1s 631ms/step - loss: 0.0735 - mae: 0.1832 - val_loss: 0.0690 - val_mae: 0.1727\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 1s 626ms/step - loss: 0.0834 - mae: 0.1941 - val_loss: 0.0547 - val_mae: 0.1572\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.1017 - mae: 0.2196 - val_loss: 0.0665 - val_mae: 0.1718\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 0.0853 - mae: 0.2046 - val_loss: 0.0437 - val_mae: 0.1482\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.0770 - mae: 0.1936 - val_loss: 0.0417 - val_mae: 0.1383\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 1s 643ms/step - loss: 0.0843 - mae: 0.2013 - val_loss: 0.0442 - val_mae: 0.1415\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.0961 - mae: 0.2092 - val_loss: 0.0700 - val_mae: 0.1683\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.0840 - mae: 0.1931 - val_loss: 0.0461 - val_mae: 0.1389\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.0773 - mae: 0.1805 - val_loss: 0.0673 - val_mae: 0.1545\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.0740 - mae: 0.1751 - val_loss: 0.0844 - val_mae: 0.1747\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.0940 - mae: 0.1953 - val_loss: 0.0699 - val_mae: 0.1534\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 1s 620ms/step - loss: 0.0763 - mae: 0.1776 - val_loss: 0.0616 - val_mae: 0.1467\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.0808 - mae: 0.1826 - val_loss: 0.0648 - val_mae: 0.1496\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 1s 620ms/step - loss: 0.0948 - mae: 0.1982 - val_loss: 0.0451 - val_mae: 0.1334\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 1s 622ms/step - loss: 0.0772 - mae: 0.1800 - val_loss: 0.0524 - val_mae: 0.1395\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.0863 - mae: 0.1903 - val_loss: 0.0588 - val_mae: 0.1499\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.0647 - mae: 0.1694 - val_loss: 0.0391 - val_mae: 0.1300\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.0844 - mae: 0.1918 - val_loss: 0.0542 - val_mae: 0.1475\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 0.0891 - mae: 0.1971 - val_loss: 0.0535 - val_mae: 0.1464\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.0919 - mae: 0.2040 - val_loss: 0.0196 - val_mae: 0.1051\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 1s 617ms/step - loss: 0.0769 - mae: 0.1860 - val_loss: 0.0521 - val_mae: 0.1444\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.0709 - mae: 0.1798 - val_loss: 0.0619 - val_mae: 0.1559\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 1s 611ms/step - loss: 0.0688 - mae: 0.1726 - val_loss: 0.0561 - val_mae: 0.1502\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.0868 - mae: 0.1894 - val_loss: 0.0777 - val_mae: 0.1710\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.0688 - mae: 0.1685 - val_loss: 0.0826 - val_mae: 0.1722\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 1s 634ms/step - loss: 0.0834 - mae: 0.1871 - val_loss: 0.0373 - val_mae: 0.1225\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.0781 - mae: 0.1833 - val_loss: 0.0604 - val_mae: 0.1500\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 1s 627ms/step - loss: 0.0826 - mae: 0.1862 - val_loss: 0.0596 - val_mae: 0.1474\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 1s 634ms/step - loss: 0.0682 - mae: 0.1676 - val_loss: 0.0524 - val_mae: 0.1439\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.0812 - mae: 0.1813 - val_loss: 0.0406 - val_mae: 0.1243\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.0916 - mae: 0.1950 - val_loss: 0.0539 - val_mae: 0.1395\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.0922 - mae: 0.1987 - val_loss: 0.0709 - val_mae: 0.1624\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 1s 616ms/step - loss: 0.0804 - mae: 0.1879 - val_loss: 0.0609 - val_mae: 0.1575\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 1s 617ms/step - loss: 0.0827 - mae: 0.1888 - val_loss: 0.0511 - val_mae: 0.1488\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.0687 - mae: 0.1744 - val_loss: 0.0737 - val_mae: 0.1630\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 1s 627ms/step - loss: 0.0758 - mae: 0.1755 - val_loss: 0.0293 - val_mae: 0.1104\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 1s 631ms/step - loss: 0.0870 - mae: 0.1916 - val_loss: 0.0558 - val_mae: 0.1374\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.0770 - mae: 0.1819 - val_loss: 0.0368 - val_mae: 0.1163\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.0926 - mae: 0.2033 - val_loss: 0.0320 - val_mae: 0.1100\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 1s 633ms/step - loss: 0.0863 - mae: 0.1901 - val_loss: 0.0506 - val_mae: 0.1367\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 1s 638ms/step - loss: 0.0785 - mae: 0.1799 - val_loss: 0.0703 - val_mae: 0.1629\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.0820 - mae: 0.1856 - val_loss: 0.0710 - val_mae: 0.1698\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.0659 - mae: 0.1698 - val_loss: 0.0500 - val_mae: 0.1421\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.0785 - mae: 0.1812 - val_loss: 0.0385 - val_mae: 0.1249\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.0791 - mae: 0.1840 - val_loss: 0.0354 - val_mae: 0.1218\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.0778 - mae: 0.1818 - val_loss: 0.0777 - val_mae: 0.1679\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.0947 - mae: 0.2017 - val_loss: 0.0377 - val_mae: 0.1201\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.0699 - mae: 0.1721 - val_loss: 0.0354 - val_mae: 0.1218\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.0687 - mae: 0.1680 - val_loss: 0.0606 - val_mae: 0.1472\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 1s 624ms/step - loss: 0.0676 - mae: 0.1682 - val_loss: 0.0709 - val_mae: 0.1586\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.0591 - mae: 0.1571 - val_loss: 0.0525 - val_mae: 0.1358\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.0754 - mae: 0.1742 - val_loss: 0.0328 - val_mae: 0.1119\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.0743 - mae: 0.1748 - val_loss: 0.0482 - val_mae: 0.1297\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 1s 623ms/step - loss: 0.0740 - mae: 0.1722 - val_loss: 0.0308 - val_mae: 0.1108\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 1s 639ms/step - loss: 0.0771 - mae: 0.1739 - val_loss: 0.0652 - val_mae: 0.1544\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 1s 626ms/step - loss: 0.0765 - mae: 0.1736 - val_loss: 0.0404 - val_mae: 0.1265\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.0715 - mae: 0.1697 - val_loss: 0.0183 - val_mae: 0.0962\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.0975 - mae: 0.2005 - val_loss: 0.0590 - val_mae: 0.1432\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.0780 - mae: 0.1833 - val_loss: 0.0286 - val_mae: 0.1116\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.0693 - mae: 0.1723 - val_loss: 0.0540 - val_mae: 0.1389\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.0756 - mae: 0.1767 - val_loss: 0.0301 - val_mae: 0.1143\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.0543 - mae: 0.1515 - val_loss: 0.0615 - val_mae: 0.1468\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.0818 - mae: 0.1795 - val_loss: 0.0317 - val_mae: 0.1122\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 1s 634ms/step - loss: 0.0813 - mae: 0.1809 - val_loss: 0.0354 - val_mae: 0.1141\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.0728 - mae: 0.1714 - val_loss: 0.0427 - val_mae: 0.1234\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.0715 - mae: 0.1713 - val_loss: 0.0471 - val_mae: 0.1299\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.0655 - mae: 0.1609 - val_loss: 0.0536 - val_mae: 0.1400\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.0726 - mae: 0.1680 - val_loss: 0.0657 - val_mae: 0.1567\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 1s 634ms/step - loss: 0.0766 - mae: 0.1768 - val_loss: 0.0570 - val_mae: 0.1538\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.0505 - mae: 0.1461\n",
            "Validation loss: 0.05053343251347542 \n",
            "Validation MAE: 0.1461120843887329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f93c97326d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeOylvqXOVQb"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvlMxALqOcvJ",
        "outputId": "a0de5fe2-e8ec-471e-cd02-0652da5f2d95"
      },
      "source": [
        "print('Predicting the next four weeks for all counties ...')\n",
        "seriesall = predict_multistep_timeseries(data_train_valid, \n",
        "                                            counties,\n",
        "                                            mean_train, \n",
        "                                            std_train, \n",
        "                                            model,)\n",
        "seriesall_bck = seriesall\n",
        "seriesall = seriesall.clip(min=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting the next four weeks for all counties ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInDKolwOfGz"
      },
      "source": [
        "# Evaluation of predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-88heQnjxTw",
        "outputId": "b5f955f0-b978-4944-c100-63f8fb10310e"
      },
      "source": [
        "# Evaluate the predictions for all counties\n",
        "print('Evaluation of predictions ...')\n",
        "rmse_county = pd.DataFrame(index=(list(pd.unique(data_train_valid.GISJOIN))), \n",
        "                            columns=['rmse_confirmed', 'rmse_death'])\n",
        "\n",
        "rmse_weekly = pd.DataFrame(index=['w' + str(x) for x in list(range(1, PRED_WEEKS+1))], \n",
        "                            columns=['rmse_confirmed', 'rmse_death'])\n",
        "\n",
        "rmse_all = pd.DataFrame(index=['all'], \n",
        "                        columns=['rmse_confirmed', 'rmse_death'])\n",
        "\n",
        "# RMSE by county (see equation 7 in paper)\n",
        "for item in list(pd.unique(data_train_valid.GISJOIN)):\n",
        "\n",
        "    smplCntyIdx = list(pd.unique(data_train_valid.GISJOIN)).index(item)\n",
        "    mask = data.loc[:, 'GISJOIN'] == item\n",
        "    d = data.loc[mask, ['confirmed_cases', 'deaths']]\n",
        "    series = d.to_numpy()\n",
        "\n",
        "    rmse_county.loc[item, ['rmse_confirmed']] = np.sqrt(mean_squared_error(series[-PRED_WEEKS:, 0], seriesall[smplCntyIdx,-PRED_WEEKS:, 0]))\n",
        "    \n",
        "    rmse_county.loc[item, ['rmse_death']] = np.sqrt(mean_squared_error(series[-PRED_WEEKS:, 1], seriesall[smplCntyIdx,-PRED_WEEKS:, 1]))\n",
        "\n",
        "data2 = np.array(data.loc[:, ['confirmed_cases', 'deaths']]).reshape((len(counties), TIMESERIES_LENGHT, 2))\n",
        "\n",
        "# RMSE by week (see equation 8 in paper)\n",
        "for w in rmse_weekly.index:\n",
        "    rmse_weekly.loc[w,'rmse_confirmed'] = np.sqrt(mean_squared_error(data2[:, -(PRED_WEEKS-int(w[1])+1), 0], seriesall[:,-(PRED_WEEKS-int(w[1])+1), 0]))\n",
        "    rmse_weekly.loc[w,'rmse_death'] = np.sqrt(mean_squared_error(data2[:, -(PRED_WEEKS-int(w[1])+1), 1], seriesall[:,-(PRED_WEEKS-int(w[1])+1), 1]))\n",
        "\n",
        "print('RMSE by week', rmse_weekly)\n",
        "\n",
        "# RMSE total (see equation 9 in paper)\n",
        "rmse_all.loc['all','rmse_confirmed'] = np.sqrt(mean_squared_error(data2[:, -PRED_WEEKS:, 0], seriesall[:,-PRED_WEEKS:, 0]))\n",
        "rmse_all.loc['all','rmse_death'] = np.sqrt(mean_squared_error(data2[:, -PRED_WEEKS:, 1], seriesall[:,-PRED_WEEKS:, 1]))\n",
        "\n",
        "print('\\n RMSE (total)', rmse_all)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation of predictions ...\n",
            "RMSE by week    rmse_confirmed rmse_death\n",
            "w1        283.969    9.99319\n",
            "w2        229.122    8.58614\n",
            "w3        223.273    8.32907\n",
            "w4        167.366     8.0922\n",
            "\n",
            " RMSE (total)     rmse_confirmed rmse_death\n",
            "all        229.672    8.78127\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
